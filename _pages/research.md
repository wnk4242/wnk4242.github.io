---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---
## Research Replicability
Over the last decade, psychology has faced a replication crisis because efforts to replicate past study findings often fail to yield consistent results. Psychologists have conducted several large-scale multi-lab replication projects (such as the Many Labs series) to reassess the replicability of earlier findings. Major funding agencies (such as the National Science Foundation and the National Institute of Health) have specific programs that offer funding opportunities to advance the science of replicability. I am currently pursuing three lines of research to enhance our understanding of research replicability, and I will delineate them in the following sections.

- The application of Bayesian meta-analysis in studies of research replicability

   Psychologists are currently faced with a pressing methodological challenge: developing a universally accepted, empirically validated framework to evaluate outcomes of replications. I propose adopting the Bayesian 
   hypothesis testing within a meta-analytic framework and explore how well such an approach answers the following question: _“Do the pooled data from all replications support or refute the presence of the psychological 
   effect?”_ More importantly, my research expands our understanding by answering an essential follow-up question: _“How often are our conclusions about the replicability of original studies incorrect, based on their 
   replications?”_ Moving forward, my aim is to apply the advancements from my current research to empirical replication data. This effort aligns with my long-term objective of developing a statistical framework designed to 
   assess the replications of advanced and complex research designs. 

- Effect size, heterogeneity, and power of exact replications

   Effect-size variability (also known as heterogeneity), is a key methodological factor that is frequently neglected in planning the sample sizes for replication studies. My research investigates several fundamental 
   questions regarding heterogeneity in replication studies and examines how the potentially linear relationship between effect sizes and heterogeneity may impact the statistical power of replications. Gaining a better 
   understanding of heterogeneity is key to improving sample size planning for future multi-lab replication projects. Moving forward, I plan to assess the impact of power analysis methods that account for heterogeneity 
   compared to traditional methods that typically ignore it. My ultimate goal is to develop strategies for determining optimal sample sizes and the appropriate number of replications.

- Credibility of research findings in educational psychology
  
   Statistical power plays a key role in ensuring the reliability, precision, and replicability of effect size estimation. In psychology, the average power is distressingly low—estimated at 36% with only 8% of studies deemed 
   adequately powered. The impact of such issues on educational psychology has not received the attention it deserves. I am currently researching the credibility (true positive rate) of meta-analyses published in five 
   leading educational psychology journals between 2012 and 2022. Completion of this work will raise awareness within the academic community about the prevalence of under-powered research in top-tier journals. 
